{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM wch1.ipynb","provenance":[],"authorship_tag":"ABX9TyNAads3jUyyH+Lxgqx8ngLf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCRuKfrl4o5b","executionInfo":{"status":"ok","timestamp":1653910713235,"user_tz":-420,"elapsed":4533,"user":{"displayName":"Aishy","userId":"07523823037401625626"}},"outputId":"d6a3ee6c-8c44-4dc6-e325-047a83c87fd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import numpy\n","import re\n","import pandas as pd\n","import numpy as np\n","import keras\n","import string\n","import nltk\n","nltk.download('punkt')\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","\n","string.punctuation = string.punctuation +'“'+'”'+'-'+'’'+'‘'+'—'\n","string.punctuation = string.punctuation.replace('.', '')"]},{"cell_type":"code","source":["# Loads the data and preprocesses data and stores corpus in raw_text\n","raw_text = open('wonderland_ch1.txt', encoding = 'utf8').read()\n","\n","file_nl_removed = \"\"\n","for line in raw_text:\n","  line_nl_removed = line.replace(\"\\n\", \" \")           \n","#removes newlines\n","  file_nl_removed += line_nl_removed\n","\n","file_p = \"\".join([char for char in file_nl_removed if char not in string.punctuation])   \n","#removes all special characters\n","sents = nltk.sent_tokenize(file_p)\n","print(\"The number of sentences is\", len(sents)) \n","#prints the number of sentences\n","\n","string.punctuation = string.punctuation + '.'\n","file_q = \"\".join([char for char in file_p if char not in string.punctuation])   #removes even periods.\n","words = nltk.word_tokenize(file_q)\n","print(\"The number of tokens is\", len(words)) \n","#prints the number of tokens\n","\n","average_tokens = round(len(words)/len(sents))\n","print(\"The average number of tokens per sentence is\", average_tokens) \n","#prints the average number of tokens per sentence\n","\n","unique_tokens = set(words)\n","print(\"The number of unique tokens are\", len(unique_tokens)) \n","#prints the number of unique tokens\n","\n","preprocessed_text = file_p.lower()       \n","#converts corpus into lowercase"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHLsEWJx4r7f","executionInfo":{"status":"ok","timestamp":1653910738404,"user_tz":-420,"elapsed":344,"user":{"displayName":"Aishy","userId":"07523823037401625626"}},"outputId":"15e8c156-5445-4a61-bda7-04fa101d5f0a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of sentences is 43\n","The number of tokens is 2140\n","The average number of tokens per sentence is 50\n","The number of unique tokens are 651\n"]}]},{"cell_type":"code","source":["# Uses the preprocessed data and create raw_text\n","raw_text = preprocessed_text   #periods have not been removed for better results\n","\n","# creates mapping of unique characters to integers\n","chars = sorted(list(set(raw_text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","int_to_char = dict((i, c) for i, c in enumerate(chars))\n","# Prints the total characters and character vocab size\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","\n","print(\"The number of total characters are\", n_chars)\n","print(\"\\nThe character vocab size is\", n_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_z16IBNP5HHx","executionInfo":{"status":"ok","timestamp":1653910821767,"user_tz":-420,"elapsed":17,"user":{"displayName":"Aishy","userId":"07523823037401625626"}},"outputId":"fc72e94b-3f51-46ab-9f03-e4592cd8603e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of total characters are 10801\n","\n","The character vocab size is 28\n"]}]},{"cell_type":"code","source":["#Prepares dataset where the input is sequence of 100 characters and target is next character.\n","seq_length = 100\n","\n","dataX = []\n","dataY = []\n","\n","for i in range(0, n_chars - seq_length, 1):\n","  seq_in = raw_text[i:i + seq_length]\n","  seq_out = raw_text[i + seq_length]\n","\n","  dataX.append([char_to_int[char] for char in seq_in])\n","  dataY.append(char_to_int[seq_out])\n","\n","n_patterns = len(dataX)\n","print (\"Total Patterns: \", n_patterns)\n","# reshapes X to be [samples, time steps, features]\n","X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n","\n","# one hot encodes the output variable\n","y = np_utils.to_categorical(dataY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xr-aR5907kQQ","executionInfo":{"status":"ok","timestamp":1653910856155,"user_tz":-420,"elapsed":532,"user":{"displayName":"Aishy","userId":"07523823037401625626"}},"outputId":"b32481ae-a9e2-4efa-a888-cee815102696"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Patterns:  10701\n"]}]},{"cell_type":"code","source":["embedding_dim =100\n","max_length =100\n","\n","model1 = Sequential()\n","model1.add(Embedding(n_vocab, embedding_dim, input_length=max_length))\n","model1.add(LSTM(256, input_shape=(X.shape[1], embedding_dim),return_sequences=True))\n","model1.add(Dropout(0.2))\n","model1.add(LSTM(256))\n","model1.add(Dropout(0.2))\n","model1.add(Dense(y.shape[1], activation='softmax'))\n","model1.compile(loss='categorical_crossentropy', optimizer='adam')\n","model1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROfgfCFN5KbD","executionInfo":{"status":"ok","timestamp":1653910873247,"user_tz":-420,"elapsed":2233,"user":{"displayName":"Aishy","userId":"07523823037401625626"}},"outputId":"5ae94e3e-3f30-4152-f5a4-4287a7456285"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 100, 100)          2800      \n","                                                                 \n"," lstm (LSTM)                 (None, 100, 256)          365568    \n","                                                                 \n"," dropout (Dropout)           (None, 100, 256)          0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 256)               525312    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 28)                7196      \n","                                                                 \n","=================================================================\n","Total params: 900,876\n","Trainable params: 900,876\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Uses validation split of 0.2 while training\n","history = model1.fit(X, y, epochs = 20, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lOTVSCf5ORq","outputId":"7f397a20-10c8-4a5f-a4c4-81c06922640c","executionInfo":{"status":"ok","timestamp":1653915443925,"user_tz":-420,"elapsed":4548478,"user":{"displayName":"Aishy","userId":"07523823037401625626"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","168/168 [==============================] - 233s 1s/step - loss: 2.8372\n","Epoch 2/20\n","168/168 [==============================] - 225s 1s/step - loss: 2.4752\n","Epoch 3/20\n","168/168 [==============================] - 226s 1s/step - loss: 2.1973\n","Epoch 4/20\n","168/168 [==============================] - 227s 1s/step - loss: 2.0430\n","Epoch 5/20\n","168/168 [==============================] - 227s 1s/step - loss: 1.8975\n","Epoch 6/20\n","168/168 [==============================] - 237s 1s/step - loss: 1.7533\n","Epoch 7/20\n","168/168 [==============================] - 231s 1s/step - loss: 1.6259\n","Epoch 8/20\n","168/168 [==============================] - 228s 1s/step - loss: 1.5138\n","Epoch 9/20\n","168/168 [==============================] - 226s 1s/step - loss: 1.4099\n","Epoch 10/20\n","168/168 [==============================] - 226s 1s/step - loss: 1.2929\n","Epoch 11/20\n","168/168 [==============================] - 227s 1s/step - loss: 1.1953\n","Epoch 12/20\n","168/168 [==============================] - 227s 1s/step - loss: 1.0847\n","Epoch 13/20\n","168/168 [==============================] - 226s 1s/step - loss: 0.9863\n","Epoch 14/20\n","168/168 [==============================] - 225s 1s/step - loss: 0.8828\n","Epoch 15/20\n","168/168 [==============================] - 224s 1s/step - loss: 0.7839\n","Epoch 16/20\n","168/168 [==============================] - 229s 1s/step - loss: 0.7003\n","Epoch 17/20\n","168/168 [==============================] - 226s 1s/step - loss: 0.6364\n","Epoch 18/20\n","168/168 [==============================] - 226s 1s/step - loss: 0.5544\n","Epoch 19/20\n","168/168 [==============================] - 227s 1s/step - loss: 0.4842\n","Epoch 20/20\n","168/168 [==============================] - 226s 1s/step - loss: 0.4323\n"]}]},{"cell_type":"code","source":["# Generates the sequence similar to above methods. Gets the generated string using the model.\n","def predict_next_n_chars(pattern, n):\n","    for i in range(n):\n","      x = numpy.reshape(pattern, (1, len(pattern), 1))\n","      prediction = model1.predict(x, verbose=0)\n","      print (int_to_char[numpy.argmax(prediction)], end = '')   #get next char index.\n","      seq_in = [int_to_char[value] for value in pattern]\n","      pattern.append(numpy.argmax(prediction))\n","      pattern = pattern[1:len(pattern)]"],"metadata":{"id":"GrkM3ANp67sU","executionInfo":{"status":"ok","timestamp":1653915497446,"user_tz":-420,"elapsed":544,"user":{"displayName":"Aishy","userId":"07523823037401625626"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#picks a random seed\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","input_str = ''.join([int_to_char[value] for value in pattern])\n","print (\"Seed -\",  input_str, sep = '\\n\\n')\n","print (\"\\nGenerated string -\\n\")\n","\n","predict_next_n_chars(pattern, 200)\n","# specifies an unseen input string\n","input_str = \"The boy laughed at the fright he had caused. This time, the villagers left angrily. The third day, as the boy went up\\\n"," the small hill, he suddenly saw a wolf attacking his sheep. He cried as hard as he could, “Wolf! Wolf! Wolf!”, but not \\\n"," a single villager came to help him. The villagers thought that he was trying to fool them again and did not come to rescue \\\n"," him or his sheep.\"\n","\n","#Uses the first 100 characters from given input_str as input to generate next 200 characters. \n","input_str = input_str.lower()\n","input_string = ''\n","for each in input_str:\n","  if each in chars:\n","    if (len (input_string)<100):\n","      input_string += each\n","\n","pattern = []\n","pattern.append([char_to_int[char] for char in input_string])\n","\n","print (\"Seed -\",  input_str, sep = '\\n\\n')\n","print (\"\\nGenerated string -\\n\")\n","predict_next_n_chars(pattern[0], 200)"],"metadata":{"id":"MgPQ2H1a8Lx2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653915562244,"user_tz":-420,"elapsed":31990,"user":{"displayName":"Aishy","userId":"07523823037401625626"}},"outputId":"59ae7e03-7ab6-4a3a-eab5-96035553e1cb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Seed -\n","\n","sidering how in the world she was to get out again.  the rabbithole went straight on like a tunnel f\n","\n","Generated string -\n","\n","or some way and stupid for life to go on in the country is you know. please maam is this no use in crying to do that said alice it was all very well to say drink me but the was not a moment she troundSeed -\n","\n","the boy laughed at the fright he had caused. this time, the villagers left angrily. the third day, as the boy went up the small hill, he suddenly saw a wolf attacking his sheep. he cried as hard as he could, “wolf! wolf! wolf!”, but not  a single villager came to help him. the villagers thought that he was trying to fool them again and did not come to rescue  him or his sheep.\n","\n","Generated string -\n","\n","it was all very well to say drink me but the was not a moment she tround the door and see the remame of the country is you know. please maam is this no use in crying to do that said alice it was all v"]}]}]}